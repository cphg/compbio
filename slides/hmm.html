---
layout: aakrosh_markdown
title: "Hidden Markov Models (HMMs)"
---

## {{page.title}}
![hmm](images/hmm/hiddenmarkov.svg)

Note: HMMs are well-known for their effectiveness in modeling the correlations between adjacent symbols, domains, or events, and they have been extensively used in various fields, especially in speech recognition and digital communication. Considering the remarkable success of HMMs in engineering, it is no surprise that a wide range of problems in biological sequence analysis have also benefited from them. 


---

## What do you remember about dynamic programming?

What is dynamic programming really?


- introduced in 1950s by Richard Bellman of Rand Corp <!-- .element : class="fragment" data-fragment-index="1" --> <!-- .element : class="fragment" data-fragment-index="1" -->
- it's hard to define  <!-- .element : class="fragment" data-fragment-index="1" --> 
- it's extremely broad <!-- .element : class="fragment" data-fragment-index="1" --> 


[The theory of dynamic programming](https://www.ams.org/journals/bull/1954-60-06/S0002-9904-1954-09848-8/)  <!-- .element : class="fragment" data-fragment-index="1" --> 



---

## The setting

![example](images/hmm/dynamic-programming-1.png)

---

## The insight

![example](images/hmm/dynamic-programming-2.png)

The essence of dynamic programming is "do the best you can from where you are" <!-- .element : class="fragment" --> 



---

Consider a process determined at any time by an M-dimensional vector

$$
\mathbf{p} = (x_0, x_1, x_2, ..., x_m)
$$

Consider a set of transformations $\mathbf{T} = { T_k }$,  
which are functions that transform $\mathbf{p}$  

$$
T_k(p)
$$

We want to maximize our "return" -- the output of some scalar function $R(p)$ of the final state.

---

We want to select a series of transformations,  
called "policy" $P=(T_1, T_2, ... T_N)$,  
which will yield successive states:

$$
p_1 = T_1(p_0)  \\\\
p_2 = T_2(p_1)  \\\\
...... \\\\
p_N = T_N(p_{N-1})
$$

The maximum value of $R(P_N)$, determined by an optimal policy, will only be a function of the initial vector $p_0$ and the number of stages N.

$$ 
f_N(p) = Max_{P}R(p_N)
$$

---

$$ 
f_N(p) = Max_{P}R(p_N)
$$

Choose our first transformation $T_1(p_0)$.  
The maximum return from the following (N-1) stages is by definition:

$$
f_{N-1}(T_1(p_0)) \\\\
= f_{N-1}(p_1)
$$




Thus:

$$
f_N(p) = Max_{P}R(p_N) = Max_{k} f_{N-1}(T_k(p))
$$

Which means: at any given time, we must choose the transformation that maximizes the return.


---

## Dynamic programming: the gist

You have a sequence of states, and at each time step, you make a decision. You want to end optimally, for some definition of optimal. 

The brute-force way is to consider all possible sequences of decisions and then pick the best one, but this is not possible for long sequences with many possible decisions. <!-- .element : class="fragment" --> 

Instead, divide the problem into sub-problems: At any particular time determining your decision payoff depends only on the current state of the system, not on later states of the system. <!-- .element : class="fragment" --> 

This concept can apply to a huge array of problems, from investing to aircraft control to...computational biology. <!-- .element : class="fragment" --> 


---

## A toy HMM for 5′ splice site recognition
![example](images/hmm/example.jpg.webp)

<small>[What is a hidden Markov model?](https://www.nature.com/articles/nbt1004-1315)

Note: Often, biological sequence analysis is just a matter of putting the right label on each residue. In gene identification, we want to label nucleotides as exons, introns, or intergenic sequence. In sequence alignment, we want to associate residues in a query sequence with homologous residues in a target database sequence. We can always write an ad hoc program for any given problem, but the same frustrating issues will always recur. One is that we want to incorporate heterogeneous sources of information. A genefinder, for instance, ought to combine splice-site consensus, codon bias, exon/ intron length preferences and open reading frame analysis into one scoring system. How should these parameters be set? How should different kinds of information be weighted? A second issue is to interpret results probabilistically. Finding a best scoring answer is one thing, but what does the score mean, and how confident are we that the best scoring answer is correct? A third issue is extensibility. The moment we perfect our ad hoc genefinder, we wish we had also modeled translational initiation consensus, alternative splicing and a polyadenylation signal. Too often, piling more reality onto a fragile ad hoc program makes it collapse under its own weight.

---

## Hidden Markov Models (HMMs)
* Provide a foundation for probabilistic models of linear sequence ‘labeling’ problems
* Can be designed just by drawing a graph diagram
* Originally developed for applications to voice recognition
* Applications include: Gene prediction, protein secondary structure prediction, copy-number variation, chromatin-state assignment, chromatin topology ...

Note: Joint probability $P(A,B) = P(A|B)  P(B) = P(B|A)  P(A)$, Marginal probability $P(X=A) = \sum_y P(X=A, Y=y_i)$

---

## Markov models 

## &darr; 

## Hidden Markov models

---

## Markov Models
* Set of states: ${s_1, s_2, \ldots, s_n}$
* Process moves from one state to another generating a sequence of states: $s_{i1}, s_{i2}, \ldots, s_{ik}, \ldots$
* Markov property:  The probability of each symbol depends only on the preceding symbol, not the entire previous sequence  
  $$P(s_{ik}|s_{i1},s_{i2},\ldots,s_{i(k-1)}) = P(s_{ik}|s_{i(k-1)})$$

* A Markov chain is defined by:
  * transition probabilities $A=(a_{ij}), a_{ij} = P(s_i, s_j)$
  * initial probabilities: $\pi=(\pi_i), \pi_i = P(s_i)$

---

## Example 
![markov](images/hmm/markov.svg) <!-- .element width="80%" height="80%" -->

$A = \begin{bmatrix}
0.7 & 0.3\\\\\\
0.4 & 0.6
\end{bmatrix}$,
$\pi = (0.4, 0.6)$

Note: So let's consider I have two coins, one of them is fair and the other one is loaded. 

---

## Calculation of sequence probability


Multiplication Rule of probability:

$$
P(A, B) = P(A|B) P(B)
$$

By Markov property, probability of state sequence can be found by the formula

$$\begin{eqnarray}
P(s_{i1}, \ldots, s_{ik}) &=& P(s_{ik} | s_{i1}, \ldots, s_{i(k-1)}) P(s_{i1}, \ldots, s_{i(k-1)})\\\\\\
&=& P(s_{ik} | s_{i(k-1)}) P(s_{i1}, s_{i2}, \ldots, s_{i(k-1)})\\\\\\
&=& \ldots\\\\\\
&=& P(s_{ik} | s_{i(k-1)}) \ldots P(s_{i2} | s_{i1}) P(s_{i1}) 
\end{eqnarray}$$

---

## Calculation of sequence probability
![markov](images/hmm/markov.svg) <!-- .element width="80%" height="80%" -->

$\pi = (0.4, 0.6)$

Suppose we want to calculate $P(L,L,F,F)$

$$\begin{eqnarray}
P(L,L,F,F) &=& P(F|L,L,F) P(L,L,F) \\\\\\
&=& P(F|F) P(F|L,L) P(L,L)\\\\\\
&=& P(F|F) P(F|L) P(L|L) P(L)\\\\\\
&=& 0.7 \times 0.4 \times 0.6 \times 0.6
\end{eqnarray}$$

---

## Hidden Markov Models
* Set of states: ${s_1, s_2, \ldots, s_n}$
* Process moves from one state to another generating a sequence of states: $s_{i1}, s_{i2}, \ldots, s_{ik}, \ldots$
* Markov chain property: $$P(s_{ik}|s_{i1},s_{i2},\ldots,s_{i(k-1)}) = P(s_{ik}|s_{i(k-1)})$$
* States are not visible, but each state randomly generates one of $M$ observations (or emissions): ${o_1, o_2, \ldots, o_l}$ <!-- .element : class="fragment" data-fragment-index="1" -->

---

## Components of Hidden Markov Models

The following need to be defined for Model $M = (A, B, \pi)$:

* transition probabilities:  
   $ \mathbf{A} = \\{ a_{ij} \\} $  
   $a_{ij} = P(s_i \rightarrow s_j)$
* initial probabilities:  
  $\pi= \\{ \pi_i \\}$  
  $\pi_i = P(s_i)$
* observation/emission probabilities:  
  $\mathbf{B} = \\{ b_i(v_m) \\}$  
  $b_i(v_m) = P(v_m | s_i)$

<!-- ---

## Components of an HMM

- transition from state $k$ to state $l$: $\mathbf{A} = {a_{kl}}$
  - initiation probabilities: $a_{0k}$, or $\pi$
- emission probabilities: $\mathbf{B} = {e_k}$
 -->

---

## Example 
![hidden_markov](images/hmm/hiddenmarkov.svg) <!-- .element width="60%" height="60%" -->

$A = \begin{bmatrix}
0.7 & 0.3\\\\\\
0.4 & 0.6
\end{bmatrix}$,
$B = \begin{bmatrix}
0.5 & 0.5\\\\\\
0.3 & 0.7
\end{bmatrix}$,
$\pi = (0.4, 0.6)$

---

## Calculation of sequence probability
Suppose we want to calculate $P( \\{ H,H \\} )$

$$\begin{eqnarray}
P( \\{ H,H \\} ) &=& P( \\{ H,H \\}, \\{ F,F \\}) + \\\\\\
& & P( \\{ H,H \\}, \\{ F,L \\}) +\\\\\\
& & P( \\{ H,H \\}, \\{ L,F \\}) +\\\\\\
& & P( \\{ H,H \\}, \\{ L,L \\})
\end{eqnarray}$$

$$\begin{eqnarray}
P( \\{ H,H \\}, \\{ F,F \\}) &=& P( \\{ H,H \\} | \\{ F,F \\}) P(\\{ F,F \\})\\\\\\
&=& P(H|F) P(H|F) P(F|F) P(F)
\end{eqnarray}$$

Note: Consider all possible hidden state sequences

---

## 3 Computational applications of HMMs
* Decoding problem (aka uncovering, parsing, or inference)

Given an HMM $M=(A,B,\pi)$, and an observation sequence $O$, find the sequence of states most likely to have produced $O$. <!-- .element : class="fragment" data-fragment-index="1" -->

* Likelihood problem (aka evaluation, or scoring)

Given an HMM $M=(A,B,\pi)$, and an observation sequence $O, o_i \in {v_1,v_2,\ldots,v_M}$, calculate likelihood $P(O|M)$. <!-- .element : class="fragment" data-fragment-index="2" -->


* Learning problem (aka parameter estimation, or fitting)

Given an HMM structure and observation sequence $O$, determine HMM parameters that best fit the training data. <!-- .element : class="fragment" data-fragment-index="3" -->


---

## Solutions to 3 applications of HMMs

* Decoding problem (aka uncovering, parsing, or inference)

Viterbi algorithm <!-- .element : class="fragment" data-fragment-index="1" -->

* Likelihood problem (aka evaluation, or scoring)

Forward-backward algorithm <!-- .element : class="fragment" data-fragment-index="2" -->

* Learning problem (aka parameter estimation, or fitting)

Baum-Welch algorithm <!-- .element : class="fragment" data-fragment-index="3" -->

---

## Decoding problem 

Given HMM $M=(A,B,\pi)$ and observation sequence $O$, find the sequence of states most likely to produce $O$.

![decoding](images/hmm/decoding1.png)

---

## Decoding problem 
![decoding](images/hmm/decoding1.png)

$P(O, S)$: the probability that HMM follows sequence of states $S$ and emits string $O$.

$$P(O,S) = P(O_{1:T}, S_{1:T}) = P(O_{1:T}|S_{1:T}) P(S_{1:T})$$
$P(O_{1:T}|S_{1:T})$: product of emission probabilities,  
$P(S_{1:T})$: product of transition probabilities

---

## Decoding problem

Find $S_{1:T}$ that maximises $P(O_{1:T}|S_{1:T})$ over all possible paths in the HMM

![decoding](images/hmm/decoding1.png)

$M$ states, $T$ time steps: $M^T$ paths...

---

## Viterbi algorithm

* Dynamic programming
* $M$ rows (number of states), $T$ columns (length of sequence)
* Initialization: $S_{i, 1} = \pi_i B(O_1|S_i)$
* Recursion: $S_{i,j} = \max_k S_{k,j-1} a_{ki} B(O_j|S_i)$

![recursion](images/hmm/decoding1.png)

---

## Viterbi algorithm
![hidden_markov](images/hmm/hiddenmarkov.svg) <!-- .element width="50%" height="50%" -->

Observations : HHTTTTTTTH, $\pi=(0.5,0.5)$

---

## Viterbi algorithm

Use log space to avoid numerical underflow

![hidden_markov](images/hmm/hiddenmarkovlog.svg) <!-- .element width="40%" height="40%" -->

Observations : HHTTTTTTTH, $\pi=c(-0.69,-0.69)$

![dp](images/hmm/dp1.svg) <!-- .element : class="fragment" data-fragment-index="1" -->

---

## Viterbi algorithm
![hidden_markov](images/hmm/hiddenmarkovlog.svg) <!-- .element width="50%" height="50%" -->

Observations : HHTTTTTTTH, $\pi=c(-0.69,-0.69)$

![dp](images/hmm/dp2.svg) 

Note: log(state prior * state emission) -0.69 - 0.69

---

## Viterbi algorithm
![hidden_markov](images/hmm/hiddenmarkovlog.svg) <!-- .element width="50%" height="50%" -->

Observations : HHTTTTTTTH, $\pi=c(-0.69,-0.69)$

![dp](images/hmm/dp3.svg) 

Note: log(state prior * state emission). -1.2 - 0.69

---

## Viterbi algorithm
![hidden_markov](images/hmm/hiddenmarkovlog.svg) <!-- .element width="50%" height="50%" -->

![dp](images/hmm/dp4.svg) 

Note: -1.39 - 0.36 - .69 = -2.44, -1.9 - 0.92 - 0.69 = -3.51 

---

## Viterbi algorithm
![hidden_markov](images/hmm/hiddenmarkovlog.svg) <!-- .element width="50%" height="50%" -->

![dp](images/hmm/dp5.svg) 

Note: -1.39 - 1.20 - 1.20 = -3.79, -1.9 - 0.51 - 1.20 = -3.60 

---

## Viterbi algorithm
![hidden_markov](images/hmm/hiddenmarkovlog.svg) <!-- .element width="50%" height="50%" -->

![dp](images/hmm/dp6.svg) 

---

## Viterbi algorithm
![hidden_markov](images/hmm/hiddenmarkovlog.svg) <!-- .element width="50%" height="50%" -->

![dp](images/hmm/dp7.svg) 

---

## Viterbi algorithm
![hidden_markov](images/hmm/hiddenmarkovlog.svg) <!-- .element width="50%" height="50%" -->

![dp](images/hmm/dp8.svg) 

---

## Viterbi algorithm
![hidden_markov](images/hmm/hiddenmarkovlog.svg) <!-- .element width="50%" height="50%" -->

![dp](images/hmm/dp9.svg) 

---

## Likelihood problem
Given the HMM $M=(A,B,\pi)$, and an observation sequence $O$, calculate likelihood $P(O|M)$.

$$P(O|S) = \prod_{i=1}^T P(O_i|S_i)$$  <!-- .element : class="fragment" data-fragment-index="1" -->

But we do not know the state sequence! <!-- .element : class="fragment" data-fragment-index="2" -->

---

## Likelihood problem

So, we must sum over all possible state sequences.

$$\begin{eqnarray}
P(O) &=& \sum_{S} P(O,S) \\\\\\
&=& \sum_{S} P(O|S) P(S)
\end{eqnarray}$$

Note: we can compute the total probability of the observations just by summing over all possible hidden state sequences. Again, for M states and T time steps, we are talking M^T paths

---

## Likelihood problem
![trellis](images/hmm/decoding.png)

Initialization: $\alpha_1(i) = \pi_i B(O_1|S_i)$

Recursion: $\alpha_{t+1}(i) = \sum_i \alpha_t(i) a_{ij} B(O_{t+1}|S_i)$

$$P(O|M) = \sum_{i=1}^M \alpha_{T}(i)$$

---

## Likelihood problem

![trellis](images/hmm/decoding.png)

Initialization: $\beta_{T^*}(i) = 1$

Recursion: $\beta_{t}(i) = \sum_j \beta_{t+1}(j) a_{ij} B(O_{t+1}|S_j)$

$$P(O|M) = \sum_{i=1}^M \pi_i B(O_1|S_i) \beta_{T}(i)$$

Note: You can solve the likelihood problem using the forward procedure, or the backwards procedure.


---
# Forward vs viterbi

The only difference between Forward and Viterbi is  
you sum over all the possible paths instead of 
choosing the maximum:


Viterbi recursion step:

$ v_l(i) = e_l(x_i) \times max_k(v_k(i-1)a_{kl}) $

Forward algorithm recursion step:

$ f_l(i) = e_l(x_i) \times \sum_{k}{f_k(i-1)a_{kl}} $


---

## Forward-Backward algorithm
$\alpha$ : Probability of the state for observations now and before this time<br>
$\beta$  : Probability of the state for observations after this time

![forwardbackward](images/hmm/forwardbackward.png)

Note: Because we are interested in comparison of states at each time point, we have to scale it. So we will calculate alpha-3F * beta3F / sum(alpha_iF*beta_iF). So when using this method, we also get some confidence values associated with our determination of the most likely state

---

## Learning problem

Given observation sequence $O$, and general structure of HMM, determine HMM parameters that best fit the training data. 

### Learning with annotated training data <!-- .element : class="fragment" data-fragment-index="1" -->

If we had training data: A sequence of observations, with a known state sequence <!-- .element : class="fragment" data-fragment-index="1" -->

We could just use maximum likelihood. We could compute: <!-- .element : class="fragment" data-fragment-index="1" -->
- emission probability for each state <!-- .element : class="fragment" data-fragment-index="1" -->
- transition probabilities for each state  <!-- .element : class="fragment" data-fragment-index="1" -->
- initial state probabilities <!-- .element : class="fragment" data-fragment-index="1" -->

We have defined the model. <!-- .element : class="fragment" data-fragment-index="1" -->

Problem: What if we don't have known state sequences? <!-- .element : class="fragment" data-fragment-index="2" -->

---

### Learning *without* annotated training data

* Input is only observations: $O_1, O_2, \ldots, O_T$
* Baum-Welch algorithm (EM algorithm)
* not guaranteed to be optimal

E-step (expectation):
- Compute a best guess path through the model (state sequence)

M-stem (maximization):
- Adjust transition/emission probabilities as if the best guess is accurate.

---

## Estimating parameters for coin flips
![visible](images/hmm/baum1.svg)

---

## Estimating parameters for coin flips
![visible](images/hmm/baum2.svg)

$P(H|F), P(T|F), P(H|L), P(T|L)$ <!-- .element : class="fragment" data-fragment-index="1" -->

$P(F|F), P(F|L), P(L|F), P(L|L)$ <!-- .element : class="fragment" data-fragment-index="2" -->

Note: Consider a fully visible Markov model. This would easily allow us to compute the HMM parameters just by maximum likelihood estimation from the training data. For a real HMM, we cannot compute these counts directly from an observation sequence since we don’t know which path of states was taken through the machine for a given input. The Baum-Welch algorithm solves this by iteratively estimating the counts. We will start with an estimate for the transition and observation probabilities and then use these estimated probabilities and use the forward-backward procedure to determine the probability of the states at each observation. Then we can use that to determine better estimates of the transition and emission probabilities. 

---

## Baum-Welch algorithm

$$\hat{a_{ij}} = \frac{\textrm{expected number of transitions from state } i \textrm{ to state }j} {\textrm{expected number of transitions from state }i}$$

$P(S_t = i, S_{t+1} = j, O) = \alpha_t(i)a_{ij}B(O_{t+1}|S_j) \beta_{t+1}(j)$

![joint](images/hmm/joint.png)

Note: How do we compute the numerator? Here’s the intuition. Assume we had some estimate of the probability that a given transition i → j was taken at a particular point in time t in the observation sequence. If we knew this probability for each particular time t, we could sum over all times t to estimate the total count for the transition i → j.

---

## Baum-Welch algorithm

$$\begin{eqnarray}
P(S_t = i, S_{t+1} = j | O) &=& \frac{P(S_t = i, S_{t+1} = j, O)}{P(O)}\\\\\\
&=& \frac{\alpha_t(i)a_{ij}B(O_{t+1}|S_j) \beta_{t+1}(j)}{\sum_{j=1}^N \alpha_t(j) \beta_t(j)}
\end{eqnarray}$$

$$\hat{a_{ij}} = \frac{\sum_{t=1}^{T-1} P(S_t = i, S_{t+1} = j | O)}{\sum_{t=1}^{T-1} \sum_{k=1}^M P(S_t = i, S_{t+1} = k | O)}$$

---

## Baum-Welch algorithm

$$\hat{b_j(v_k)} = \frac{\textrm{expected number of times in state } j \textrm{ and observing } v_k} {\textrm{expected number of times in state }j}$$

$P(S_t = j, O) = \alpha_t(j) \beta_t(j)$

![joint2](images/hmm/joint2.png)

---

## Baum-Welch algorithm

$$\begin{eqnarray}
P(S_t = j | O) &=& \frac{P(S_t = j, O)}{P(O)}\\\\\\
&=& \frac{\alpha_t(j) \beta_{t}(j)}{\sum_{j=1}^N \alpha_t(j) \beta_t(j)}
\end{eqnarray}$$

$$\hat{b_j(v_k)} = \frac{\sum_{t=1\ s.t.\ O_t=v_k}^{T} P(S_t = j | O)}{\sum_{t=1}^{T} P(S_t = j | O)}$$

---

## Advantages and limitations

* Modularity : HMMs can be combined into larger HMMs
* Transparency : Based on a state model making it interpretable
* Prior knowledge: can be incorporated in the model

* Need accurate, applicable, and sufficiently sized training sets of data
* Model may not converge to a true optimum
* Can be slow in comparison to other methods

---
## Applications

1. ChromHMM: chromatin state segmentation
2. HMMer: protein homology search
3. Universe-HMM: consensus interval sets

---

## ChromHMM

> ChromHMM is a Java program for learning and characterizing chromatin states using a multivariate Hidden Markov Model that models the combinatorial and spatial patterns in data from multiple chromatin marks.

---
ChromHMM Input is a binary matrix of chromatin mark presence/absence across genomic tiles.


- Columns are chromatin marks  
- Rows are genomic tiles

Example:

```console
Cell chr1
Mark1 Mark2 Mark3
0 0 0
0 1 0
0 0 1
```

---

ChromHMM output is a segmentation that divides the genome into chromatin states.

Example

![example](images/hmm/segments.png)

---

## HMMEr

> HMMER is a software package that provides tools for making
probabilistic models of protein and DNA sequence domain families –
called profile hidden Markov models, profile HMMs, or just profiles
– and for using these profiles to annotate new sequences, to search
sequence databases for additional homologs, and to make deep multiple sequence alignments

---

HMMer input is a protein multiple-sequence alignment

Example:

![example](images/hmm/hmmer-globins-sto.png)

---

HMMer learns an HMM model from the input

```
hmmbuild globins4.hmm globins4.sto
```
![example](images/hmm/hmmer-model.png)

---

Trained HMMer models can be used  
to search sequence databases  
for other sequences that match the alignment.

---

## Consensus region set  HMM

> In our model, there are three observed sequences: the number of starts, overlaps, and ends at a given position. The hidden variable corresponds to the different parts of the flexible segment. We can tune transition probabilities, which can be chosen in a way that will prevent unnecessary segmentation, and emission matrix, which describes the relationship between observations and hidden states.  

---

Region set HMM input is a collection of region sets,  
which is transformed into counts of starts, overlap, and ends

![example](images/hmm/universe-regions.svg) <!-- .element style="background:white" -->

Output is a unified segmentation, a consensus region set

---
